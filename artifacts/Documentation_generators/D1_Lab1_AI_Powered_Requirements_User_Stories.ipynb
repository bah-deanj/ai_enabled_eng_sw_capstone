{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Lab 1: AI-Powered Requirements & User Stories\n",
    "\n",
    "**Objective:** Use a Large Language Model (LLM) to decompose a vague problem statement into structured features, user personas, and Agile user stories, culminating in a machine-readable JSON artifact.\n",
    "\n",
    "**Estimated Time:** 90 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Welcome to the first hands-on lab of the AI-Driven Software Engineering Program! All great software projects begin with a clear understanding of the problem to be solved. In this lab, you will take on the role of a tech lead or product manager and use an LLM as a co-pilot to transform a simple, high-level problem into a set of well-defined, actionable requirements. This process is fundamental to ensuring that the team builds the *right* product.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "This initial block sets up our environment. It adds the project's root directory to the Python path, allowing us to import our custom `utils.py` script. We then initialize the connection to our Large Language Model (LLM).\n",
    "\n",
    "**Model Selection:**\n",
    "Our `utils.py` script is configured to work with multiple AI providers. You can change the `model_name` parameter in the `setup_llm_client()` function to any of the models listed in the `RECOMMENDED_MODELS` dictionary in `utils.py`. For example, to use a Hugging Face model, you could change the line to: `client, model_name, api_provider = setup_llm_client(model_name=\"meta-llama/Llama-3.3-70B-Instruct\")`\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client for our chosen LLM.\n",
    "- `get_completion()`: To send a prompt to the LLM and get a response.\n",
    "- `save_artifact()`: To save our generated requirements to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'openai' with model 'gpt-4.1'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    # Assumes the notebook is in 'labs/Day_01_.../'\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from app.agent.utils import setup_llm_client, get_completion, save_artifact\n",
    "\n",
    "# Initialize the LLM client. You can change the model here.\n",
    "# For example: setup_llm_client(model_name=\"gemini-2.5-flash\")\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Problem Statement\n",
    "\n",
    "Every project starts with a problem. Our problem is a common one in many organizations:\n",
    "\n",
    "> **\"We need a tool to help our company's new hires get up to speed.\"**\n",
    "\n",
    "This statement is intentionally vague. Our job is to use the LLM to add structure and detail to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_statement = \"We need a tool to give recipie suggestions based on ingredients we have at home.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The Challenges\n",
    "\n",
    "Complete the following challenges in order. Each one builds upon the last, increasing in technical complexity and value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Brainstorming Features\n",
    "\n",
    "**Task:** Use the LLM to brainstorm a list of potential features and user personas based on the problem statement.\n",
    "\n",
    "**Instructions:**\n",
    "1. Write a simple prompt that asks the LLM to brainstorm features for the onboarding tool.\n",
    "2. Write a second prompt to identify three distinct user personas who would use this tool.\n",
    "3. Run both prompts and review the markdown output.\n",
    "\n",
    "**Expected Quality:** The output should be a simple, readable markdown list of features and a description of the personas. This is a good first step but lacks the structure needed for automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Brainstorming Features ---\n",
      "- Ingredient Input (manual entry and scanning/barcode support)\n",
      "- Pantry Inventory Management\n",
      "- Smart Recipe Suggestions Based on Available Ingredients\n",
      "- Filter Recipes by Dietary Preferences (vegan, gluten-free, etc.)\n",
      "- Save Favorite Recipes\n",
      "- Shopping List Generator for Missing Ingredients\n",
      "- Meal Planning and Scheduling Calendar\n",
      "- Recipe Rating and Review System\n",
      "- Suggest Substitutions for Missing Ingredients\n",
      "- Portion Size Adjustment\n",
      "- Cooking Time and Difficulty Filters\n",
      "- Integration with Grocery Delivery Services\n",
      "- Voice Assistant Support for Hands-Free Usage\n",
      "- Nutritional Information Display\n",
      "- Option to Add Custom Recipes\n",
      "- Step-by-Step Cooking Instructions\n",
      "- Allergen Warnings and Filters\n",
      "- Multi-User/Family Account Support\n",
      "- Export/Share Recipes with Others\n",
      "- Seasonal Ingredient Suggestions\n",
      "\n",
      "--- Identifying User Personas ---\n",
      "```markdown\n",
      "## Persona 1: Busy Professional\n",
      "\n",
      "- **Name:** Alex Chen\n",
      "- **Age:** 29\n",
      "- **Occupation:** Software Developer\n",
      "- **Motivation:** Wants to quickly prepare meals after work without extra trips to the store.\n",
      "- **Challenges:** Has limited time to plan meals and often finds random ingredients in the fridge.\n",
      "- **Needs:** Simple, fast recipe suggestions using what’s already at home.\n",
      "\n",
      "---\n",
      "\n",
      "## Persona 2: College Student\n",
      "\n",
      "- **Name:** Maya Patel\n",
      "- **Age:** 20\n",
      "- **Occupation:** Undergraduate Student\n",
      "- **Motivation:** Needs to make affordable meals with what’s available in her dorm kitchen.\n",
      "- **Challenges:** Limited budget and kitchen equipment, often has odd leftover ingredients.\n",
      "- **Needs:** Creative, low-cost recipes based on a small selection of ingredients.\n",
      "\n",
      "---\n",
      "\n",
      "## Persona 3: Family Caregiver\n",
      "\n",
      "- **Name:** Sarah Martinez\n",
      "- **Age:** 42\n",
      "- **Occupation:** Stay-at-home Parent\n",
      "- **Motivation:** Wants to reduce food waste and prepare nutritious meals for her family.\n",
      "- **Challenges:** Managing a busy household and using up perishable items before they spoil.\n",
      "- **Needs:** Family-friendly recipe ideas that incorporate available ingredients and minimize waste.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a string variable named 'features_prompt'.\n",
    "# This prompt should ask the LLM to brainstorm features based on the problem_statement.\n",
    "features_prompt = f\"\"\" Based on the following problem statement, brainstorm a list of potential features for a software tool that\n",
    "could help address the issue. \n",
    "Output the features in markdown forat. Only output markdown and no additional text.\n",
    "Problem Statement: {problem_statement}\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Brainstorming Features ---\")\n",
    "brainstormed_features = get_completion(features_prompt, client, model_name, api_provider)\n",
    "print(brainstormed_features)\n",
    "\n",
    "# TODO: Create a string variable named 'personas_prompt'.\n",
    "# This prompt should ask the LLM to identify three user personas based on the problem_statement.\n",
    "personas_prompt = f\"\"\"Identify three distinct user personas who would benefit from a tool that addresses the problem statement below.\n",
    "Output the personas in markdown format. Only output markdown and no additional text.\n",
    "Problem Statement: {problem_statement}\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Identifying User Personas ---\")\n",
    "user_personas = get_completion(personas_prompt, client, model_name, api_provider)\n",
    "print(user_personas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Formal User Stories\n",
    "\n",
    "**Task:** Now, let's increase the value by generating structured, formal Agile User Stories.\n",
    "\n",
    "**Instructions:**\n",
    "1. Create a new, more sophisticated prompt.\n",
    "2. This prompt should instruct the LLM to act as a Senior Product Manager.\n",
    "3. It must use the brainstormed features and personas from the previous step as context.\n",
    "4. The key instruction is to generate a list of user stories, each with detailed acceptance criteria in Gherkin format (`Given/When/Then`).\n",
    "5. **Crucially, the prompt must demand the final output be a well-formed JSON array of objects.** Each object should represent a user story and have keys like `id`, `user_story`, `persona`, and `acceptance_criteria`.\n",
    "\n",
    "> **Tip:** If the LLM's output isn't perfect JSON, try making your prompt even more specific. You can tell it, 'Do not include any text before or after the JSON array. Your response must begin with [ and end with ].'\n",
    "\n",
    "**Expected Quality:** The output should not be markdown, but a clean, parsable JSON string. This is a significant step up in value, as a JSON artifact can be automatically processed by other systems (e.g., imported into Jira)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating User Stories as JSON ---\n",
      "Successfully parsed LLM output as JSON.\n",
      "\n",
      "--- Sample User Story ---\n",
      "{\n",
      "  \"id\": \"1\",\n",
      "  \"persona\": \"Busy Professional\",\n",
      "  \"user_story\": \"As a busy professional, I want to quickly input the ingredients I have (by typing or scanning), so I can get recipe suggestions without wasting time.\",\n",
      "  \"acceptance_criteria\": [\n",
      "    \"Given I have ingredients at home, When I open the app, Then I can manually enter or scan/barcode my ingredients into my pantry list.\",\n",
      "    \"Given I have scanned or entered ingredients, When I view my pantry, Then I see an updated list of available items.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a detailed prompt string named 'json_user_stories_prompt'.\n",
    "# This prompt needs to instruct the LLM to act as a Senior Product Manager and convert the\n",
    "# brainstormed features and personas into a structured JSON array of user stories.\n",
    "# Tip: Be very specific about the required JSON format in your prompt instructions. Tell it what keys to use and what the data types should be.\n",
    "json_user_stories_prompt = f\"\"\" \n",
    "# You are a Certified Master Chef. Based on the problem statement, the brainstormed features, and the identified user personas below, \n",
    "# create a structured JSON array of user stories.\n",
    "Each user story should be a JSON object with the following keys:\n",
    "- id (string): A unique integer identifier for the user story.\n",
    "- persona (string): A string representing the user persona associated with the story.\n",
    "- user_story (string): The user persona that will benefit from the feature.\n",
    "- acceptance_criteria (array of strings): A list of criteria in Gherkin format that must be met for the story to be considered complete.\n",
    "\n",
    "User Personas:\n",
    "{user_personas}\n",
    "\n",
    "Brainstormed Features:\n",
    "{brainstormed_features}\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating User Stories as JSON ---\")\n",
    "json_output_str = get_completion(json_user_stories_prompt, client, model_name, api_provider, temperature=0.2)\n",
    "\n",
    "# Let's try to parse the JSON to see if the LLM followed instructions\n",
    "try:\n",
    "    # The LLM might wrap the JSON in markdown fences (```json ... ```).\n",
    "    # We'll clean that up before parsing.\n",
    "    if '```' in json_output_str:\n",
    "        json_output_str = json_output_str.split('```')[1].lstrip('json').strip()\n",
    "    \n",
    "    user_stories_json = json.loads(json_output_str)\n",
    "    print(\"Successfully parsed LLM output as JSON.\")\n",
    "    \n",
    "    if user_stories_json:\n",
    "        print(\"\\n--- Sample User Story ---\")\n",
    "        print(json.dumps(user_stories_json[0], indent=2))\n",
    "    else:\n",
    "        print(\"JSON array is empty.\")\n",
    "\n",
    "except (json.JSONDecodeError, TypeError, IndexError) as e:\n",
    "    print(f\"Error: Failed to parse LLM output as JSON. Error: {e}\")\n",
    "    print(\"LLM Output was:\\n\", json_output_str)\n",
    "    user_stories_json = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Programmatic Validation and Artifact Creation\n",
    "\n",
    "**Task:** Now for the highest-value step. Instead of just looking at the JSON, we will programmatically validate it and save it as a formal project artifact. This ensures reliability and prepares the requirements for automated use in later stages of the SDLC.\n",
    "\n",
    "**Instructions:**\n",
    "1. Complete the `validate_and_save_stories` function below.\n",
    "2. The function should iterate through the list of stories.\n",
    "3. For each story, it must validate that the required keys are present and that the acceptance criteria list is not empty.\n",
    "4. If all stories are valid, it should save the data to `artifacts/day1_user_stories.json`.\n",
    "\n",
    "**Expected Quality:** A robust script that guarantees the integrity of our requirements artifact. The final output is a validated `day1_user_stories.json` file in the `artifacts` directory, ready to be used as a reliable input for Day 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All user stories passed validation.\n",
      "✅ Successfully saved artifact to: artifacts\\PRD_recipies.json\n"
     ]
    }
   ],
   "source": [
    "def validate_and_save_stories(stories_data):\n",
    "    \"\"\"Validates the structure of the user stories data and saves it if valid.\"\"\"\n",
    "    if not isinstance(stories_data, list) or not stories_data:\n",
    "        print(\"Validation Failed: Data is not a non-empty list.\")\n",
    "        return\n",
    "\n",
    "    required_keys = ['id', 'persona', 'user_story', 'acceptance_criteria']\n",
    "    all_stories_valid = True\n",
    "\n",
    "    # TODO: Implement the validation logic inside this function.\n",
    "    # 1. Loop through each story in the 'stories_data' list.\n",
    "    # 2. For each story, check if it contains all the 'required_keys'.\n",
    "    # 3. Also check if the 'acceptance_criteria' list is not empty.\n",
    "    # 4. If a story is invalid, print an error message and set 'all_stories_valid' to False.\n",
    "    #    (You can use 'continue' to skip to the next story).\n",
    "    for story in stories_data:\n",
    "        if not isinstance(story, dict):\n",
    "            print(f\"Validation Failed: Story is not a dictionary: {story}\")\n",
    "            all_stories_valid = False\n",
    "            break\n",
    "        \n",
    "        missing_keys = [key for key in required_keys if key not in story]\n",
    "        if missing_keys:\n",
    "            print(f\"Validation Failed: Story is missing keys {missing_keys}: {story}\")\n",
    "            all_stories_valid = False\n",
    "            break\n",
    "        \n",
    "        if not isinstance(story['acceptance_criteria'], list) or not story['acceptance_criteria']:\n",
    "            print(f\"Validation Failed: 'acceptance_criteria' is not a non-empty list in story: {story}\")\n",
    "            all_stories_valid = False\n",
    "            break\n",
    "\n",
    "    # Your validation code here\n",
    "\n",
    "    if all_stories_valid:\n",
    "        print(\"\\nAll user stories passed validation.\")\n",
    "        artifact_path = \"artifacts/PRD_recipies.json\"\n",
    "        \n",
    "        # TODO: Call the save_artifact function from utils.py to save the data.\n",
    "        # Remember to convert the Python list back to a JSON string using json.dumps().\n",
    "        save_artifact(json.dumps(stories_data, indent=2), artifact_path)\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nValidation failed. Artifact not saved.\")\n",
    "\n",
    "# Run the validation on the JSON data from the previous step\n",
    "if 'user_stories_json' in locals() and user_stories_json:\n",
    "    validate_and_save_stories(user_stories_json)\n",
    "else:\n",
    "    print(\"Skipping validation as user_stories_json is empty or not defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Congratulations! You have completed the first lab. You started with a vague, one-sentence problem and finished with a structured, validated, machine-readable requirements artifact. This is the critical first step in an AI-assisted software development lifecycle. The `day1_user_stories.json` file you created will be the direct input for our next lab, where we will generate a formal Product Requirements Document (PRD).\n",
    "\n",
    "> **Key Takeaway:** The single most important skill demonstrated in this lab is turning unstructured ideas into structured, machine-readable data (JSON). This transformation is what enables automation and integration with other tools later in the SDLC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
