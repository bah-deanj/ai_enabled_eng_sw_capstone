{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 2: Documenting Key Decisions with ADRs\n",
    "\n",
    "**Objective:** Use an LLM as a research assistant to compare technical options and synthesize the findings into a formal, version-controlled Architectural Decision Record (ADR).\n",
    "\n",
    "**Estimated Time:** 60 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Great architectural decisions are based on research and trade-offs. A critical practice for healthy, long-lived projects is documenting *why* these decisions were made. In this lab, you will use an LLM to research a key technical choice for our application and then generate a formal ADR to record that decision for the future.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We'll start by ensuring our environment is ready and adding the standard pathing solution to reliably import our `utils.py` helper.\n",
    "\n",
    "**Model Selection:**\n",
    "For research and synthesis tasks, models with large context windows and strong reasoning abilities are ideal. `gpt-4.1`, `gemini-2.5-pro`, or `meta-llama/Llama-3.3-70B-Instruct` would be excellent choices.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the ADR template.\n",
    "- `save_artifact()`: To save the generated ADR template and the final ADR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'openai' with model 'gpt-4.1'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from app.agent.utils import setup_llm_client, get_completion, save_artifact, load_artifact\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): The ADR Template\n",
    "\n",
    "**Task:** A good ADR follows a consistent format. Your first task is to prompt an LLM to generate a clean, reusable ADR template in markdown.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt that asks the LLM to generate a markdown template for an Architectural Decision Record.\n",
    "2.  The template should include sections for: `Title`, `Status` (e.g., Proposed, Accepted, Deprecated), `Context` (the problem or forces at play), `Decision` (the chosen solution), and `Consequences` (the positive and negative results of the decision).\n",
    "3.  Save the generated template to `templates/adr_template.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating ADR Template ---\n",
      "```markdown\n",
      "# [Title]\n",
      "\n",
      "**Status:** [Proposed | Accepted | Deprecated]\n",
      "\n",
      "## Context\n",
      "\n",
      "_What is the problem being addressed? What are the forces or concerns influencing this decision? Provide background, constraints, and any relevant context._\n",
      "\n",
      "## Decision\n",
      "\n",
      "_What is the chosen solution and why? Describe the decision made, including any alternatives considered and the reasoning behind the choice._\n",
      "\n",
      "## Consequences\n",
      "\n",
      "_What are the results of this decision? List both the positive and negative outcomes, and any follow-up actions required._\n",
      "```\n",
      "✅ Successfully saved artifact to: artifacts\\templates\\adr_template.md\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to generate a markdown ADR template.\n",
    "adr_template_prompt = \"\"\"As a research assistant, generate a markdown template for an Architecture Decision Record (ADR).\n",
    "The template should include the following sections:\n",
    "1. Title\n",
    "2. Status (e.g., Proposed, Accepted, Deprecated)\n",
    "3. Context (the problem or forces at play)\n",
    "4. Decision (the chosen solution)\n",
    "5. Consequences (the positive and negative outcomes of the decision)\n",
    "\n",
    "Output the template in markdown format without any additional text or explanation.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating ADR Template ---\")\n",
    "adr_template_content = get_completion(adr_template_prompt, client, model_name, api_provider)\n",
    "print(adr_template_content)\n",
    "\n",
    "# Save the artifact\n",
    "if adr_template_content:\n",
    "    save_artifact(adr_template_content, \"templates/adr_template.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): AI-Assisted Research\n",
    "\n",
    "**Task:** Use the LLM to perform unbiased research on a key technical decision for our project: choosing a database for semantic search.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt instructing the LLM to perform a technical comparison.\n",
    "2.  Ask it to compare and contrast two technical options: **\"Using PostgreSQL with the `pgvector` extension\"** versus **\"Using a specialized vector database like ChromaDB or FAISS\"**.\n",
    "3.  The prompt should ask for a balanced view for the specific use case of our new hire onboarding tool.\n",
    "4.  Store the output in a variable for the next step.\n",
    "\n",
    "> **Tip:** To get a balanced comparison, explicitly ask the LLM to 'act as an unbiased research assistant' and to list the 'pros and cons for each approach.' This prevents the model from simply recommending the more popular option and encourages a more critical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Researching Database Options ---\n",
      "Certainly! Here’s a balanced technical comparison for each technology choice relevant to a recipe suggestion tool, across the requested axes:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. \"Using GPT-4.1\" vs \"Other Models\" (for recipe suggestions/NLP tasks)\n",
      "\n",
      "**GPT-4.1 (e.g., via OpenAI API)**\n",
      "- **Pros:**\n",
      "  - State-of-the-art language understanding and generation.\n",
      "  - Handles complex, nuanced queries well; great for conversational UX.\n",
      "  - Well-documented, robust APIs; easy integration.\n",
      "  - Large community and ecosystem.\n",
      "- **Cons:**\n",
      "  - Can be expensive at scale (API pricing).\n",
      "  - Black-box model; limited insight into model internals.\n",
      "  - Latency can be higher than small, local models.\n",
      "  - Requires Internet access for API usage.\n",
      "\n",
      "**Other Models (e.g., Llama 3, Claude, smaller open-source models)**\n",
      "- **Pros:**\n",
      "  - Open-source models (Llama, Mistral) can be self-hosted, reducing recurring costs.\n",
      "  - More control over model customization/tuning.\n",
      "  - Some models are optimized for specific tasks/domains.\n",
      "  - Lower latency if running locally.\n",
      "- **Cons:**\n",
      "  - May require more setup and infrastructure.\n",
      "  - Generally smaller models have lower performance/accuracy.\n",
      "  - Community and documentation may be less mature.\n",
      "  - Maintenance overhead if self-hosting.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. \"Using Tavilly for Search\" vs \"Other Options\" (for searching recipes/data)\n",
      "\n",
      "**Tavilly**\n",
      "- **Pros:**\n",
      "  - Modern, open-source search engine optimized for semantic and hybrid search.\n",
      "  - Good support for vector search (useful for semantic retrieval).\n",
      "  - Simple integration with Python.\n",
      "  - Free/self-hosted, so cost-effective.\n",
      "- **Cons:**\n",
      "  - Smaller community than Elasticsearch/Typesense.\n",
      "  - Fewer advanced features than mature engines.\n",
      "  - Documentation and real-world use-cases less plentiful.\n",
      "\n",
      "**Other Options (e.g., Elasticsearch, Typesense, Meilisearch, Solr)**\n",
      "- **Pros:**\n",
      "  - Large, mature ecosystems (especially Elasticsearch/Solr).\n",
      "  - Rich features: full-text search, filtering, analytics, scalability.\n",
      "  - Good integration with many languages and frameworks.\n",
      "  - Hosted solutions available (Elasticsearch/Meilisearch).\n",
      "- **Cons:**\n",
      "  - Can be complex to deploy and manage at scale.\n",
      "  - Higher resource usage (Elasticsearch).\n",
      "  - Costly if using official hosted services.\n",
      "  - Sometimes overkill for small projects.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. \"Using sqlite3 as our db\" vs \"Other DB Tools\" (for storing recipes/users/etc.)\n",
      "\n",
      "**sqlite3**\n",
      "- **Pros:**\n",
      "  - Lightweight, serverless; no extra installation or configuration.\n",
      "  - Zero cost, embedded in Python standard library.\n",
      "  - Good for small/medium projects, prototyping, single-user or low-concurrency systems.\n",
      "  - No need to manage a running database server.\n",
      "- **Cons:**\n",
      "  - Not designed for high concurrency or large datasets.\n",
      "  - Limited scalability and performance under write-heavy loads.\n",
      "  - Lacks advanced features (e.g., replication, access control, stored procedures).\n",
      "  - Not ideal for multi-user web apps at scale.\n",
      "\n",
      "**Other DB Tools (e.g., PostgreSQL, MySQL, MongoDB, Redis)**\n",
      "- **Pros:**\n",
      "  - Designed for concurrent, large-scale, multi-user environments.\n",
      "  - Advanced features: indexing, transactions, analytics, access control.\n",
      "  - Strong community, documentation, and tooling.\n",
      "  - Cloud-hosted options and managed services available.\n",
      "- **Cons:**\n",
      "  - Requires more setup and operational overhead.\n",
      "  - Potentially higher costs (hosting, management).\n",
      "  - May be overkill for small/simple projects.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. \"Using FastAPI\" vs \"Other Options\" (for web API framework)\n",
      "\n",
      "**FastAPI**\n",
      "- **Pros:**\n",
      "  - Modern, async-friendly, high performance (based on Starlette and Pydantic).\n",
      "  - Automatic OpenAPI/Swagger docs.\n",
      "  - Type-hinting enables great editor support and code clarity.\n",
      "  - Active, growing community.\n",
      "  - Easy integration with Python ML stack.\n",
      "- **Cons:**\n",
      "  - Newer than Flask/Django; some libraries/extensions may lag.\n",
      "  - Async complexity may be overkill for simple workloads.\n",
      "  - Deployment requires understanding ASGI servers (e.g., Uvicorn).\n",
      "\n",
      "**Other Options (e.g., Flask, Django, Express.js, Spring Boot)**\n",
      "- **Pros:**\n",
      "  - Flask: Minimalist, very mature, huge ecosystem, easy for simple APIs.\n",
      "  - Django: Full-featured, batteries-included, ORM, admin.\n",
      "  - Express.js: Popular for Node.js, large community.\n",
      "  - Spring Boot: Robust for Java-based backends.\n",
      "  - Abundant resources and third-party tools.\n",
      "- **Cons:**\n",
      "  - Flask: Synchronous by default, less performant for async workloads.\n",
      "  - Django: Can be heavyweight for simple APIs; more opinionated.\n",
      "  - Express.js/Spring Boot: Not Python-based; may not fit your stack.\n",
      "  - Some frameworks require more boilerplate/setup.\n",
      "\n",
      "---\n",
      "\n",
      "## **Summary Table**\n",
      "\n",
      "| Feature/Tech           | Pros                                            | Cons                                                  |\n",
      "|------------------------|------------------------------------------------|-------------------------------------------------------|\n",
      "| GPT-4.1                | SOTA performance, easy integration, strong API | Cost, black-box, latency, needs Internet              |\n",
      "| Other Models           | Cheaper, customizable, local, lower latency    | Setup needed, smaller, less accurate, less support    |\n",
      "| Tavilly                | Modern, semantic search, easy, free            | Small community, fewer features, less documentation   |\n",
      "| Other Search Engines   | Mature, scalable, feature-rich                 | Complex, resource-heavy, costly hosted options        |\n",
      "| sqlite3                | Simple, no server, free, low setup             | Not scalable, limited features, not for high load     |\n",
      "| Other DBs              | Scalable, features, cloud options              | Setup/ops overhead, higher cost, may be overkill      |\n",
      "| FastAPI                | Async, fast, type hints, auto docs             | Newer, async complexity, ASGI server needed           |\n",
      "| Other Frameworks       | Mature, big ecosystem, simple (Flask)          | Synchronous (Flask), heavyweight (Django), not Python |\n",
      "\n",
      "**Your choices depend on project scale and priorities:**\n",
      "- For rapid prototyping or small-scale: sqlite3, FastAPI, GPT-4.1, Tavilly are attractive.\n",
      "- For production scale: PostgreSQL, Elasticsearch, possibly open-source LLMs, and a mature API framework may be preferred.\n",
      "\n",
      "Let me know if you need a decision matrix or a more detailed recommendation!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to research database options.\n",
    "db_research_prompt = \"\"\"As an unbiased research assistant, perform a balanced technical comparison of the following options:\n",
    "\"Using GPT 4.1\" vs \"other models\", \"Using Tavilly for search\" vs \"other options\", \"Using sqlite3 as our db\" vs \"other db tools\", and \"Using fastapi\" vs \"other options\" for use in our recipie suggestion tool.\n",
    "List the pros and cons of each option, considering factors such as ease of integration, performance, scalability, cost, and community support.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Researching Database Options ---\")\n",
    "db_research_output = get_completion(db_research_prompt, client, model_name, api_provider)\n",
    "print(db_research_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Synthesizing the ADR\n",
    "\n",
    "**Task:** Provide the LLM with your research from the previous step and have it formally document the decision.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Load the `adr_template.md` you created in the first challenge.\n",
    "2.  Create a new prompt instructing the LLM to act as a Staff Engineer.\n",
    "3.  Provide the `db_research_output` as context.\n",
    "4.  Instruct the LLM to populate the ADR template, formally documenting the decision to **use PostgreSQL with pgvector** and justifying the choice based on the synthesized pros and cons.\n",
    "5.  Save the final, completed ADR as `artifacts/adr_001_database_choice.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Synthesizing Final ADR ---\n",
      "```markdown\n",
      "# Architectural Decision: Use of sqlite3, Tavilly, FastAPI, and GPT-4.1 for Recipe Suggestion Tool\n",
      "\n",
      "**Status:** Accepted\n",
      "\n",
      "## Context\n",
      "\n",
      "We are building a recipe suggestion tool that requires robust natural language processing for user queries, efficient storage and retrieval of recipes and user data, and a modern web API interface. The primary priorities are rapid prototyping, low operational overhead, ease of integration with Python, and support for semantic search and conversational user experience. The anticipated usage is moderate (not high-concurrency or enterprise scale) and the goal is to validate product-market fit before considering scale-out solutions.\n",
      "\n",
      "Key concerns influencing this decision:\n",
      "- **Resource constraints:** Limited infrastructure and DevOps resources; speed of development is critical.\n",
      "- **Integration:** Preference for Python-based, modern, and actively maintained tools.\n",
      "- **Functionality:** Need for semantic search, conversational AI, and a performant web API.\n",
      "- **Cost:** Minimize expenses during early development and prototyping.\n",
      "- **Scalability:** Willing to trade off some scalability for simplicity at this stage.\n",
      "\n",
      "## Decision\n",
      "\n",
      "After evaluating alternatives, we have decided to use the following technologies as the core of our architecture:\n",
      "\n",
      "- **sqlite3** as the primary data store for recipes, users, and related metadata.\n",
      "- **Tavilly** as the search engine for semantic and hybrid search capabilities.\n",
      "- **FastAPI** as the web API framework for exposing endpoints and integrating services.\n",
      "- **GPT-4.1** (via OpenAI API) as the LLM for handling recipe suggestion, NLP tasks, and conversational UX.\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "- **sqlite3** is a lightweight, serverless, zero-cost database embedded in Python, ideal for rapid prototyping and small/medium projects. It requires minimal setup and is perfectly suited for our low-concurrency, early-stage environment.\n",
      "    - *Alternatives (PostgreSQL, MySQL, etc.)* are more robust but introduce unnecessary operational overhead for our current needs.\n",
      "\n",
      "- **Tavilly** provides semantic search capabilities with simple Python integration, is open-source and free, and is easy to self-host. Its vector search features match our need for natural language and hybrid search functionality.\n",
      "    - *Alternatives (Elasticsearch, Typesense, etc.)* are more feature-rich but are heavier to deploy, require more resources, and may be overkill for our initial scale.\n",
      "\n",
      "- **FastAPI** offers async support, high performance, automatic OpenAPI docs, and strong Python type hinting, making it a great fit for a modern, maintainable API layer with low boilerplate.\n",
      "    - *Alternatives (Flask, Django, etc.)* are either synchronous (limiting performance) or more opinionated/heavyweight than required for our needs.\n",
      "\n",
      "- **GPT-4.1** is the state-of-the-art in language models, offering excellent conversational ability and understanding for recipe suggestions and related NLP tasks. Its robust APIs and documentation reduce integration risk.\n",
      "    - *Alternatives (open-source LLMs, smaller models)* can be cheaper and self-hosted, but would require more infrastructure and likely provide less accurate results at this stage. GPT-4.1’s superior performance and ease of use outweigh its cost for early development.\n",
      "\n",
      "## Consequences\n",
      "\n",
      "**Positive Outcomes:**\n",
      "- Rapid setup and prototyping with minimal infrastructure and configuration.\n",
      "- Low operational and maintenance overhead during early stages.\n",
      "- Modern, high-quality user experience with strong NLP and semantic search.\n",
      "- Easy integration between components, all Python-friendly.\n",
      "- Cost-effective: no server/database hosting fees, and open-source search engine.\n",
      "\n",
      "**Negative Outcomes:**\n",
      "- **Scalability Limitations:** sqlite3 and Tavilly are not ideal for high-concurrency or large-scale, multi-user systems; future migration to more robust solutions may be required.\n",
      "- **Feature Limits:** Tavilly has a smaller community and fewer advanced features compared to mature search engines.\n",
      "- **GPT-4.1 API Costs:** Usage costs can increase with scale, and reliance on a 3rd-party API introduces latency and potential for outages.\n",
      "- **Future Migration:** If project grows, migration to PostgreSQL (or similar) and a more scalable search backend would be necessary, incurring technical debt.\n",
      "\n",
      "**Follow-up Actions:**\n",
      "- Monitor usage and performance; reevaluate architecture if user base or data volume grows significantly.\n",
      "- Keep schema and interfaces modular to ease future migrations.\n",
      "- Document data models and integration points to support potential technology swaps in the future.\n",
      "\n",
      "```\n",
      "✅ Successfully saved artifact to: artifacts\\adr_001_database_choice_recipies.md\n"
     ]
    }
   ],
   "source": [
    "# adr_template = load_artifact(\"templates/adr_template.md\")\n",
    "import os\n",
    "\n",
    "# The absolute path to the file\n",
    "file_path = \"c:\\\\Users\\\\labadmin\\\\Desktop\\\\capstone\\\\ai_enabled_eng_sw_capstone\\\\templates\\\\adr_template.md\"\n",
    "\n",
    "# Read the file content into the variable 'adr_template'\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    adr_template = f.read()\n",
    "\n",
    "# Now you can use the variable 'adr_template'.\n",
    "# For example, to print the content:\n",
    "# print(adr_template)\n",
    "# \n",
    "# # TODO: Write a prompt to synthesize the final ADR.\n",
    "synthesis_prompt = f\"\"\" You are a staff engineer tasked with documenting an important architectural decision using the provided \n",
    "ADR template. Formally document the decision to use \"sqlite3\", \"Tavilly\", \"FastAPI\", \"GPT 4.1\" and justify the choice based on \n",
    "the pros and cons provided in the research output.\n",
    "\n",
    "Here is the ADR template:\n",
    "{adr_template}\n",
    "\n",
    "Here is the research output:\n",
    "{db_research_output}\n",
    "\n",
    "Using the above template and research output, synthesize a complete and well-structured ADR in markdown format. \n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Synthesizing Final ADR ---\")\n",
    "if adr_template and 'db_research_output' in locals() and db_research_output:\n",
    "    final_adr = get_completion(synthesis_prompt, client, model_name, api_provider)\n",
    "    print(final_adr)\n",
    "    save_artifact(final_adr, \"adr_001_database_choice_recipies.md\")\n",
    "else:\n",
    "    print(\"Skipping ADR synthesis because template or research is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to automate a complex but critical part of the architectural process. You leveraged its vast knowledge base for research and then used it again for synthesis, turning raw analysis into a formal, structured document. This `adr_001_database_choice.md` file now serves as a permanent, valuable record for anyone who works on this project in the future.\n",
    "\n",
    "> **Key Takeaway:** The pattern of **Research -> Synthesize -> Format** is a powerful workflow. You can use an LLM to gather unstructured information and then use it again to pour that information into a structured template, creating high-quality, consistent documentation with minimal effort."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
